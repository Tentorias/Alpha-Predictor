{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a5ee4f-3287-4369-980c-ecac23feeff4",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94487a39-ee59-4788-9349-23dcf191942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# split the data imports\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a99066-30d6-4c42-82c6-bff2aef6e53f",
   "metadata": {},
   "source": [
    "# Define the parameters for data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddce699d-1db3-48b9-b25c-897bf833d92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data to PETR4.SA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\AppData\\Local\\Temp\\ipykernel_22472\\2061172975.py:19: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start_date, end=end_date)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\mathe\\AppData\\Local\\Temp\\ipykernel_22472\\2061172975.py:19: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start_date, end=end_date)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PETR4.SA data saved to: data/raw\\PETR4_raw.csv\n",
      "Downloading data to VALE3.SA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALE3.SA data saved to: data/raw\\VALE3_raw.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# stock tickers\n",
    "tickers = ['PETR4.SA', 'VALE3.SA']\n",
    "\n",
    "# Time period\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2025-01-01'\n",
    "\n",
    "# save raw data\n",
    "raw_data_path = 'data/raw'\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "os.makedirs(raw_data_path, exist_ok=True)\n",
    "\n",
    "# Collect and save data for each action\n",
    "for ticker in tickers:\n",
    "    print(f\"Downloading data to {ticker}...\")\n",
    "    \n",
    "    # Download data using the yfinance library\n",
    "    df = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "    # Check if the DataFrame is not empty\n",
    "    if not df.empty:\n",
    "        # Save the DataFrame to a CSV file inside the 'data/raw' folder\n",
    "        file_path = os.path.join(raw_data_path, f'{ticker.replace(\".SA\", \"\")}_raw.csv')\n",
    "        df.to_csv(file_path)\n",
    "        print(f\"{ticker} data saved to: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Error: Unable to download data for {ticker}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149d8589-ce81-4cac-8fbc-244762386ea5",
   "metadata": {},
   "source": [
    "Import libs, set tickers/period, download data with yf.download(), save CSV to data/raw with to_csv()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4c05d7-fc8b-4234-b090-7551f1eb448a",
   "metadata": {},
   "source": [
    "# Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6305d12e-9b11-4ed5-9284-5b36a3b130ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'Date' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- Load data from PETR4 and VALE3 ---\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m petr4_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/raw/PETR4_raw.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m vale3_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/raw/VALE3_raw.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, parse_dates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- PETR4 DataFrame analysis ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\Alpha-Predictor\\alpha_predictor_env\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Documents\\Alpha-Predictor\\alpha_predictor_env\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Documents\\Alpha-Predictor\\alpha_predictor_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Alpha-Predictor\\alpha_predictor_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\Documents\\Alpha-Predictor\\alpha_predictor_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Alpha-Predictor\\alpha_predictor_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Documents\\Alpha-Predictor\\alpha_predictor_env\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:157\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_parse_dates_presence(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames)  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_noconvert_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Alpha-Predictor\\alpha_predictor_env\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:211\u001b[0m, in \u001b[0;36mCParserWrapper._set_noconvert_columns\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    209\u001b[0m col_indices \u001b[38;5;241m=\u001b[39m [names_dict[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames]  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m noconvert_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_noconvert_dtype_columns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcol_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[has-type]\u001b[39;49;00m\n\u001b[0;32m    214\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m noconvert_columns:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mset_noconvert(col)\n",
      "File \u001b[1;32m~\\Documents\\Alpha-Predictor\\alpha_predictor_env\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:675\u001b[0m, in \u001b[0;36mParserBase._set_noconvert_dtype_columns\u001b[1;34m(self, col_indices, names)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_col, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_col:\n\u001b[1;32m--> 675\u001b[0m         noconvert_columns\u001b[38;5;241m.\u001b[39madd(\u001b[43m_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_col \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    677\u001b[0m     noconvert_columns\u001b[38;5;241m.\u001b[39madd(_set(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_col))\n",
      "File \u001b[1;32m~\\Documents\\Alpha-Predictor\\alpha_predictor_env\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:652\u001b[0m, in \u001b[0;36mParserBase._set_noconvert_dtype_columns.<locals>._set\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    649\u001b[0m     x \u001b[38;5;241m=\u001b[39m usecols[x]\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_integer(x):\n\u001b[1;32m--> 652\u001b[0m     x \u001b[38;5;241m=\u001b[39m col_indices[\u001b[43mnames\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mValueError\u001b[0m: 'Date' is not in list"
     ]
    }
   ],
   "source": [
    "# --- Load data from PETR4 and VALE3 ---\n",
    "try:\n",
    "    petr4_df = pd.read_csv('data/raw/PETR4_raw.csv', index_col='Date', parse_dates=True)\n",
    "    vale3_df = pd.read_csv('data/raw/VALE3_raw.csv', index_col='Date', parse_dates=True)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: No CSV files found. Please verify that Phase 1 was executed correctly.\")\n",
    "    exit()\n",
    "\n",
    "print(\"--- PETR4 DataFrame analysis ---\")\n",
    "print(petr4_df.head())\n",
    "\n",
    "print(\"--- VALE3 DataFrame analysis ---\")\n",
    "print(vale3_df.head())\n",
    "\n",
    "# Check data types, non-null values, and memory usage\n",
    "print(\"\\nInformation about PETR4 data:\")\n",
    "petr4_df.info()\n",
    "\n",
    "print(\"\\nInformation about VALE3 data:\")\n",
    "vale3_df.info()\n",
    "\n",
    "# Check for missing values (confirm)\n",
    "print(\"\\nChecking for null values in PETR4:\")\n",
    "print(petr4_df.isnull().sum())\n",
    "\n",
    "print(\"\\nChecking for null values in VALE3:\")\n",
    "print(vale3_df.isnull().sum())\n",
    "\n",
    "# Check for duplicates in the index (data)\n",
    "print(\"\\nChecking for duplicates in the PETR4 index (dates):\")\n",
    "print(petr4_df.index.duplicated().sum())\n",
    "\n",
    "print(\"\\Checking for duplicates in the VALE3 index (dates):\")\n",
    "print(vale3_df.index.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496f5631-75ef-41c9-af24-63f224b222c4",
   "metadata": {},
   "source": [
    "- df.info() → overview of types and nulls.\n",
    "- df.isnull().sum() → counts nulls per column.\n",
    "- df.index.duplicated().sum() → checks for duplicate dates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e9331-230a-49f7-b402-1bb988c47246",
   "metadata": {},
   "source": [
    "# Engenharia de Features e Criação da Variável-Alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08fb59a1-24cb-476b-8c6a-7c485e6a81d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'petr4_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# --- Apply the function to each DataFrame ---\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m petr4_processed_df \u001b[38;5;241m=\u001b[39m create_features(\u001b[43mpetr4_df\u001b[49m\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[0;32m     23\u001b[0m vale3_processed_df \u001b[38;5;241m=\u001b[39m create_features(vale3_df\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPETR4 DataFrame with features and target:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'petr4_df' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Function to create features and the target variable ---\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Creates predictor variables (features) and the target variable (target) in the DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # daily return\n",
    "    df[\"Daily_Return\"] = df[\"Close\"].pct_change()\n",
    "\n",
    "    # 2. Simple Moving Averages (SMA)\n",
    "    df[\"SMA_5\"] = df[\"Close\"].rolling(winodw = 5).mean()\n",
    "    df[\"SMA_10\"] = df[\"Close\"].rolling(window = 10).mean()\n",
    "    df[\"SMA_20\"] = df[\"Close\"].rolling(window = 20).mean()   \n",
    "\n",
    "    # 3. Target Variable\n",
    "    df[\"Target\"] = (df[\"Close\"].shift(-1) > df[\"Close\"]).astype(int)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "# --- Apply the function to each DataFrame ---\n",
    "petr4_processed_df = create_features(petr4_df.copy())\n",
    "vale3_processed_df = create_features(vale3_df.copy())\n",
    "\n",
    "print(\"\\nPETR4 DataFrame with features and target:\")\n",
    "print(petr4_processed_df.head())\n",
    "print(\"\\nInformation after feature engineering:\")\n",
    "petr4_processed_df.info()\n",
    "\n",
    "print(\"\\nVALE3 DataFrame with features and target:\")\n",
    "print(vale3_processed_df.head())\n",
    "print(\"\\nInformation after feature engineering:\")\n",
    "vale3_processed_df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7297088-76fe-4572-b803-1ca450d7a944",
   "metadata": {},
   "source": [
    "### 1:\n",
    "- pct_change() calculates the percentage change between the current and previous values.\n",
    "### 2:\n",
    "- window is the number of days to calculate the average.\n",
    "### 3:\n",
    "- The target variable is 1 if the next day's closing price is higher than the current day's.\n",
    "- We use .shift(-1) to compare the current price with the next day's price.\n",
    "- .astype(int) converts True/False to 1/0.\n",
    "- After calculating the features, the first 20 rows will have null values in the moving averages.\n",
    "- For the model, we need to remove these rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c23a04c-98c6-4de0-9c1c-4ea545d0e3ff",
   "metadata": {},
   "source": [
    "# split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb8143f-893b-4b9a-a787-24855f61548c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (alpha_predictor_env)",
   "language": "python",
   "name": "alpha_predictor_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
