{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a248f2a-fb11-4eed-aca2-4c4c73965828",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e8a357-fecd-43fb-b866-7dea5303e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf710f4-aeef-443a-ae8d-609a5a9bf9d4",
   "metadata": {},
   "source": [
    "# Define the parameters for data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af0ca66-c010-4c39-ae77-d85ee0a44979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data to PETR4.SA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\AppData\\Local\\Temp\\ipykernel_17172\\4216239060.py:17: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start = start_date, end = end_date)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\mathe\\AppData\\Local\\Temp\\ipykernel_17172\\4216239060.py:17: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start = start_date, end = end_date)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PETR4.SA data saved to: ../data/raw\\PETR4_raw.csv\n",
      "Downloading data to VALE3.SA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALE3.SA data saved to: ../data/raw\\VALE3_raw.csv\n",
      "\n",
      "Data collection complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# stock tickers\n",
    "tickers = ['PETR4.SA', 'VALE3.SA']\n",
    "\n",
    "# Time period\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2025-01-01'\n",
    "raw_data_path = '../data/raw'\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "os.makedirs(raw_data_path, exist_ok=True)\n",
    "\n",
    "# Collect and save data for each action\n",
    "for ticker in tickers:\n",
    "    print(f\"Downloading data to {ticker}...\")\n",
    "    \n",
    "    # Download data using the yfinance library\n",
    "    df = yf.download(ticker, start = start_date, end = end_date)\n",
    "\n",
    "    # Check if the DataFrame is not empty\n",
    "    if not df.empty:\n",
    "        # Reset the index to turn the date column into a regular column\n",
    "        df.reset_index(inplace=True)\n",
    "        \n",
    "        # Save the DataFrame to a CSV file inside the 'data/raw' folder\n",
    "        file_path = os.path.join(raw_data_path, f'{ticker.replace(\".SA\", \"\")}_raw.csv')\n",
    "        df.to_csv(file_path, index=False)\n",
    "        \n",
    "        print(f\"{ticker} data saved to: {file_path}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error: Unable to download data for {ticker}.\")\n",
    "\n",
    "print(\"\\nData collection complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6658c10f-b3d1-41a3-9c65-d34bc95c8832",
   "metadata": {},
   "source": [
    "# Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fff017e2-24ac-406e-874b-9772c48fac82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Quick Inspection for PETR4\n",
      "==================================================\n",
      "\n",
      "### First 5 lines:\n",
      "               Close      High       Low      Open      Volume\n",
      "Date                                                          \n",
      "2015-01-02  2.630870  2.807948  2.628059  2.807948  49559500.0\n",
      "2015-01-05  2.406008  2.583086  2.397576  2.569032  78385100.0\n",
      "2015-01-06  2.327308  2.481899  2.259850  2.448170  84723300.0\n",
      "2015-01-07  2.436927  2.453791  2.349793  2.406009  85531000.0\n",
      "2015-01-08  2.594330  2.639302  2.456603  2.470657  83306300.0\n",
      "\n",
      "### DataFrame Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2487 entries, 2015-01-02 to 2024-12-30\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Close   2487 non-null   float64\n",
      " 1   High    2487 non-null   float64\n",
      " 2   Low     2487 non-null   float64\n",
      " 3   Open    2487 non-null   float64\n",
      " 4   Volume  2487 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 116.6 KB\n",
      "None\n",
      "\n",
      "### Descriptive Statistics:\n",
      "             Close         High          Low         Open        Volume\n",
      "count  2487.000000  2487.000000  2487.000000  2487.000000  2.487000e+03\n",
      "mean     10.622154    10.770417    10.475020    10.623573  5.998208e+07\n",
      "std       9.033727     9.119053     8.943911     9.028086  3.325824e+07\n",
      "min       1.180519     1.200194     1.158033     1.180519  0.000000e+00\n",
      "25%       4.269590     4.348243     4.211921     4.272352  3.844015e+07\n",
      "50%       7.485869     7.579701     7.363403     7.476427  5.295610e+07\n",
      "75%      13.634948    13.830248    13.322261    13.575024  7.286525e+07\n",
      "max      35.620361    35.769546    35.199126    35.409744  4.902304e+08\n",
      "\n",
      "### Missing Values:\n",
      "Close     0\n",
      "High      0\n",
      "Low       0\n",
      "Open      0\n",
      "Volume    0\n",
      "dtype: int64\n",
      "\n",
      "### Count of Unique Values (Top 5 columns):\n",
      "- Close: 2143 unique values\n",
      "- High: 2471 unique values\n",
      "- Low: 2476 unique values\n",
      "- Open: 2477 unique values\n",
      "- Volume: 2471 unique values\n",
      "\n",
      "==================================================\n",
      "Quick Inspection for VALE3\n",
      "==================================================\n",
      "\n",
      "### First 5 lines:\n",
      "                Close       High        Low       Open     Volume\n",
      "Date                                                             \n",
      "2015-01-02  10.505504  10.836269  10.396894  10.712849  5658400.0\n",
      "2015-01-05  10.347522  10.431447  10.125367  10.248786  8603000.0\n",
      "2015-01-06  10.762214  10.925128  10.401828  10.401828  9879900.0\n",
      "2015-01-07  11.157153  11.260825  10.846135  11.018923  6130900.0\n",
      "2015-01-08  11.275641  11.295388  10.915256  11.241084  4667300.0\n",
      "\n",
      "### DataFrame Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2487 entries, 2015-01-02 to 2024-12-30\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Close   2487 non-null   float64\n",
      " 1   High    2487 non-null   float64\n",
      " 2   Low     2487 non-null   float64\n",
      " 3   Open    2487 non-null   float64\n",
      " 4   Volume  2487 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 116.6 KB\n",
      "None\n",
      "\n",
      "### Descriptive Statistics:\n",
      "             Close         High          Low         Open        Volume\n",
      "count  2487.000000  2487.000000  2487.000000  2487.000000  2.487000e+03\n",
      "mean     36.315871    36.789858    35.871997    36.352998  2.010134e+07\n",
      "std      20.979693    21.182874    20.785796    21.004941  1.350080e+07\n",
      "min       4.474547     4.713884     4.474547     4.552592  0.000000e+00\n",
      "25%      16.819281    17.030196    16.584025    16.828418  1.029180e+07\n",
      "50%      30.416147    30.772269    30.046158    30.427204  1.866250e+07\n",
      "75%      55.765425    56.345013    55.138386    55.840372  2.660340e+07\n",
      "max      76.848213    77.075623    75.585706    76.730588  1.835345e+08\n",
      "\n",
      "### Missing Values:\n",
      "Close     0\n",
      "High      0\n",
      "Low       0\n",
      "Open      0\n",
      "Volume    0\n",
      "dtype: int64\n",
      "\n",
      "### Count of Unique Values (Top 5 columns):\n",
      "- Close: 2295 unique values\n",
      "- High: 2485 unique values\n",
      "- Low: 2481 unique values\n",
      "- Open: 2484 unique values\n",
      "- Volume: 2462 unique values\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "\n",
    "tickers_no_suffix = ['PETR4', 'VALE3']\n",
    "\n",
    "# Load saved data and perform inspection\n",
    "for ticker in tickers_no_suffix:\n",
    "    file_path = f\"{raw_data_path}/{ticker}_raw.csv\"\n",
    "    \n",
    "    try:\n",
    "        # Load the file with the 'Date' column as the index\n",
    "        df = pd.read_csv(file_path, index_col='Date', parse_dates=True)\n",
    "\n",
    "        df = df.iloc[1:].copy()\n",
    "        df = df.astype('float64')\n",
    "        \n",
    "        # Ensure numeric columns are the correct type\n",
    "        numeric_cols = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "        dfs[ticker] = df\n",
    "                \n",
    "        print(f\"\\n{'=' * 50}\")\n",
    "        print(f\"Quick Inspection for {ticker}\")\n",
    "        print(f\"{'=' * 50}\")\n",
    "\n",
    "        print(\"\\n### First 5 lines:\")\n",
    "        print(df.head())\n",
    "\n",
    "        print(\"\\n### DataFrame Information:\")\n",
    "        print(df.info())\n",
    "\n",
    "        print(\"\\n### Descriptive Statistics:\")\n",
    "        print(df.describe())\n",
    "\n",
    "        print(\"\\n### Missing Values:\")\n",
    "        print(df.isnull().sum())\n",
    "        \n",
    "        print(\"\\n### Count of Unique Values (Top 5 columns):\")\n",
    "        \n",
    "        for col in df.columns[:5]:\n",
    "            print(f\"- {col}: {df[col].nunique()} unique values\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {file_path} not found. Please run the data collection step again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812c2536-8ab7-4feb-b56d-248531a80b16",
   "metadata": {},
   "source": [
    "# Engenharia de Features e Criação da Variável-Alvo com RSI e MACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "013df2c1-15b2-4dc9-b14b-3d6eefed0eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data for PETR4 with advanced features...\n",
      "Data for PETR4 processed. New shape: (2462, 9)\n",
      "Columns: ['Close', 'Volume', 'Daily_Return', 'SMA_5', 'SMA_10', 'SMA_20', 'RSI', 'MACD', 'target']\n",
      "\n",
      "Processing data for VALE3 with advanced features...\n",
      "Data for VALE3 processed. New shape: (2462, 9)\n",
      "Columns: ['Close', 'Volume', 'Daily_Return', 'SMA_5', 'SMA_10', 'SMA_20', 'RSI', 'MACD', 'target']\n",
      "\n",
      "Combined DataFrame shape: (4924, 9)\n",
      "First 5 rows:\n",
      "               Close       Volume  Daily_Return     SMA_5    SMA_10    SMA_20  \\\n",
      "Date                                                                            \n",
      "2015-02-06  2.563411  117747100.0     -0.072228  2.683150  2.635929  2.641551   \n",
      "2015-02-09  2.642112   72534200.0      0.030702  2.717441  2.623843  2.649421   \n",
      "2015-02-10  2.504385   75478700.0     -0.052128  2.657853  2.589270  2.646891   \n",
      "2015-02-11  2.552168   48681100.0      0.019080  2.605011  2.588427  2.649280   \n",
      "2015-02-12  2.656168   61706000.0      0.040749  2.583649  2.610351  2.651248   \n",
      "\n",
      "                  RSI      MACD  target  \n",
      "Date                                     \n",
      "2015-02-06  47.343509  0.034150       1  \n",
      "2015-02-09  50.237916  0.031337       0  \n",
      "2015-02-10  45.522172  0.017789       1  \n",
      "2015-02-11  47.368063  0.010783       1  \n",
      "2015-02-12  51.240525  0.013468       1  \n",
      "Processed DataFrame saved successfully.\n"
     ]
    }
   ],
   "source": [
    "for ticker in tickers_no_suffix:\n",
    "    file_path = f\"{raw_data_path}/{ticker}_raw.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, index_col='Date', parse_dates=True)\n",
    "        df = df.iloc[1:].astype('float64').copy()\n",
    "        dfs[ticker] = df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {file_path} not found.\")\n",
    "\n",
    "processed_dfs = {}\n",
    "\n",
    "for ticker, df in dfs.items():\n",
    "    print(f\"\\nProcessing data for {ticker} with advanced features...\")\n",
    "    \n",
    "    df_processed = df[['Close', 'Volume']].copy()\n",
    "    \n",
    "    # Feature Engineering\n",
    "    df_processed['Daily_Return'] = df_processed['Close'].pct_change()\n",
    "    df_processed['SMA_5'] = df_processed['Close'].rolling(5).mean()\n",
    "    df_processed['SMA_10'] = df_processed['Close'].rolling(10).mean()\n",
    "    df_processed['SMA_20'] = df_processed['Close'].rolling(20).mean()\n",
    "    df_processed['RSI'] = ta.rsi(df_processed['Close'])\n",
    "    \n",
    "    macd_result = ta.macd(df_processed['Close'])\n",
    "    df_processed['MACD'] = macd_result['MACD_12_26_9']\n",
    "    \n",
    "    df_processed['target'] = (df_processed['Close'].shift(-1) > df_processed['Close']).astype(int)\n",
    "    \n",
    "    df_processed.dropna(inplace=True)\n",
    "    processed_dfs[ticker] = df_processed\n",
    "    \n",
    "    print(f\"Data for {ticker} processed. New shape: {df_processed.shape}\")\n",
    "    print(f\"Columns: {list(df_processed.columns)}\")\n",
    "\n",
    "combined_df = pd.concat(processed_dfs.values())\n",
    "\n",
    "processed_data_path = 'data/processed'\n",
    "os.makedirs(processed_data_path, exist_ok=True)\n",
    "combined_df.to_csv(os.path.join(processed_data_path, 'combined_data.csv'))\n",
    "\n",
    "print(f\"\\nCombined DataFrame shape: {combined_df.shape}\")\n",
    "print(\"First 5 rows:\")\n",
    "print(combined_df.head())\n",
    "print(\"Processed DataFrame saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3b61ec-8433-4c55-84a7-0969aa731de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c924e3-daf1-4602-8aa8-922db054116d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (alpha_predictor_env)",
   "language": "python",
   "name": "alpha_predictor_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
